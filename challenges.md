# Scanning
 1. The lexical grammars of Python and Haskell are not regular. What does that mean, and why aren’t they?

It means they have valid sentences that can't be generated by following the rules of a regular grammar. The rules being that a valid sentence in a regular grammar must be generated by 1. A terminal character followed by a non terminal 2. A terminal character 3. The empty string. For instance, these three simple rules are not expressive enough to generate the set of all valid matching parenthesis (()(()())) since it requires a rule like ( + non terminal + ).

2. Aside from separating tokens—distinguishing print foo from printfoo—spaces aren’t used for much in most languages. However, in a couple of dark corners, a space does affect how code is parsed in CoffeeScript, Ruby, and the C preprocessor. Where and what effect does it have in each of those languages?

3. Our scanner here, like most, discards comments and whitespace since those aren’t needed by the parser. Why might you want to write a scanner that does not discard those? What would it be useful for?

4. Add support to Lox’s scanner for C-style /* ... */ block comments. Make sure to handle newlines in them. Consider allowing them to nest. Is adding support for nesting more work than you expected? Why?

It's 5am and i'll just have to come back to this later